{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hJ2_ScjiyYW",
        "outputId": "43c181da-541f-4cd3-f88f-48565631b300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/PURI/')\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE851TRVo2Xq",
        "outputId": "0cdf8d4b-94fb-4e0b-cda6-6875f9a14416"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FiveLayerResNet(nn.Module):\n",
        "    def __init__(self, num_classes=7):\n",
        "        super(FiveLayerResNet, self).__init__()\n",
        "        SQ1, SQ2, SQ3, SQ4, SQ5 = 32, 64, 128, 256, 512\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=SQ1, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(SQ1)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=SQ1, out_channels=SQ2, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(SQ2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.skip2 = nn.Sequential(\n",
        "            nn.Conv2d(SQ1, SQ2, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(SQ2)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=SQ2, out_channels=SQ3, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(SQ3)\n",
        "        self.skip3 = nn.Sequential(\n",
        "            nn.Conv2d(SQ2, SQ3, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(SQ3)\n",
        "        )\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=SQ3, out_channels=SQ4, kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(SQ4)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.skip4 = nn.Sequential(\n",
        "            nn.Conv2d(SQ3, SQ4, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(SQ4)\n",
        "        )\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=SQ4, out_channels=SQ5, kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(SQ5)\n",
        "        self.skip5 = nn.Sequential(\n",
        "            nn.Conv2d(SQ4, SQ5, kernel_size=1, bias=False),\n",
        "            nn.BatchNorm2d(SQ5)\n",
        "        )\n",
        "\n",
        "        whole_size_cons = SQ5 * 6 * 6  # 512 * 6 * 6\n",
        "        self.fc1 = nn.Linear(whole_size_cons, SQ5)\n",
        "        self.fc2 = nn.Linear(SQ5, SQ3)\n",
        "        self.fc3 = nn.Linear(SQ3, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  1\n",
        "        kv1 = self.conv1(x)\n",
        "        kv1_bn = self.bn1(kv1)\n",
        "        kv1_relu = F.relu(kv1_bn)\n",
        "        x = self.pool1(kv1_relu)\n",
        "\n",
        "        #  2 with skip\n",
        "        identity2 = self.skip2(x)\n",
        "        kv2 = self.conv2(x)\n",
        "        kv2_bn = self.bn2(kv2)\n",
        "        kv2_relu = F.relu(kv2_bn)\n",
        "        kv2_pooled = self.pool2(kv2_relu)\n",
        "        identity2_pooled = self.pool2(identity2)\n",
        "        x = kv2_pooled + identity2_pooled\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #  3 with skip\n",
        "        identity3 = self.skip3(x)\n",
        "        kv3 = self.conv3(x)\n",
        "        kv3_bn = self.bn3(kv3)\n",
        "        kv3_relu = F.relu(kv3_bn)\n",
        "        x = kv3_relu + identity3\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #  4 with skip\n",
        "        identity4 = self.skip4(x)\n",
        "        kv4 = self.conv4(x)\n",
        "        kv4_bn = self.bn4(kv4)\n",
        "        kv4_relu = F.relu(kv4_bn)\n",
        "        kv4_pooled = self.pool4(kv4_relu)\n",
        "        identity4_pooled = self.pool4(identity4)\n",
        "        x = kv4_pooled + identity4_pooled\n",
        "        x = F.relu(x)\n",
        "\n",
        "        #  5 with skip\n",
        "        identity5 = self.skip5(x)\n",
        "        kv5 = self.conv5(x)\n",
        "        kv5_bn = self.bn5(kv5)\n",
        "        kv5_relu = F.relu(kv5_bn)\n",
        "        x = kv5_relu + identity5\n",
        "        x = F.relu(x)\n",
        "        inp_br_x = x.size(0)\n",
        "        x = x.view(inp_br_x, -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "ir7TIbdlpAdC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model=None\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "save_path = '/content/drive/MyDrive/PURI/my_models/my_best_model.pth'\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = torch.load(save_path,weights_only=False)\n",
        "else:\n",
        "    model = torch.load(save_path, map_location=device, weights_only=False)\n",
        "\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3RkK3FOppBx",
        "outputId": "e97d3959-339e-4829-9673-8d457d7c8b47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "qjGEagOUKj-B",
        "outputId": "406f8ead-f4cc-40fb-e44d-76a79c1ae47e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "my_models.five_layer_batchnorm_skipping.FiveLayerResNet"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>my_models.five_layer_batchnorm_skipping.FiveLayerResNet</b><br/>def _wrapped_call_impl(*args, **kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/drive/MyDrive/PURI/my_models/five_layer_batchnorm_skipping.py</a>Base class for all neural network modules.\n",
              "\n",
              "Your models should also subclass this class.\n",
              "\n",
              "Modules can also contain other Modules, allowing them to be nested in\n",
              "a tree structure. You can assign the submodules as regular attributes::\n",
              "\n",
              "    import torch.nn as nn\n",
              "    import torch.nn.functional as F\n",
              "\n",
              "    class Model(nn.Module):\n",
              "        def __init__(self) -&gt; None:\n",
              "            super().__init__()\n",
              "            self.conv1 = nn.Conv2d(1, 20, 5)\n",
              "            self.conv2 = nn.Conv2d(20, 20, 5)\n",
              "\n",
              "        def forward(self, x):\n",
              "            x = F.relu(self.conv1(x))\n",
              "            return F.relu(self.conv2(x))\n",
              "\n",
              "Submodules assigned in this way will be registered, and will also have their\n",
              "parameters converted when you call :meth:`to`, etc.\n",
              "\n",
              ".. note::\n",
              "    As per the example above, an ``__init__()`` call to the parent class\n",
              "    must be made before assignment on the child.\n",
              "\n",
              ":ivar training: Boolean represents whether this module is in training or\n",
              "                evaluation mode.\n",
              ":vartype training: bool</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 43);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WT7dw71MzZMS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/drive/MyDrive/PURI/data')\n",
        "try:\n",
        "    from my_data_folder.my_transformations import VAL_TRANSFORM\n",
        "    from my_data_folder.my_data import load_my_data, FER2013Dataset\n",
        "    print(\" Imports worked\")\n",
        "except ImportError as e:\n",
        "    print(f\"Import failed: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8a8YMGAqx2x",
        "outputId": "448192fa-8676-4350-f06a-902106a112f6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Imports worked\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, val_df, test_df = load_my_data()\n",
        "\n",
        "if test_df is not None:\n",
        "    print(f\"Test data loaded\")\n",
        "    print(f\"Test dataset size: {len(test_df)}\")\n",
        "    print(f\"Emotions in test set:\")\n",
        "    print(test_df['emotion'].value_counts().sort_index())\n",
        "else:\n",
        "    print(\" Could not load test data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtIles1osye3",
        "outputId": "d55036e7-384a-4622-c62a-17d98a2cf944"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Using FER2013 from MyDrive\n",
            "Train : 28709\n",
            "Validation : 3589\n",
            "Test : 3589\n",
            "Test data loaded\n",
            "Test dataset size: 3589\n",
            "Emotions in test set:\n",
            "emotion\n",
            "0    467\n",
            "1     56\n",
            "2    496\n",
            "3    895\n",
            "4    653\n",
            "5    415\n",
            "6    607\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "test_dataset = FER2013Dataset(test_df, transform=VAL_TRANSFORM)\n",
        "\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=100,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "print(f\"Test loader created successfully\")\n",
        "print(f\"Number of batches: {len(test_loader)}\")\n",
        "print(f\"Total test samples: {len(test_dataset)}\")\n",
        "print(f\"Batch size: 100\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lnZDqOjtaYA",
        "outputId": "5ef9cd30-f4cb-4467-e32f-18ec1b8390d5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loader created successfully\n",
            "Number of batches: 36\n",
            "Total test samples: 3589\n",
            "Batch size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n"
      ],
      "metadata": {
        "id": "u9uKnOzGtqRY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_labels = [\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"]\n",
        "\n",
        "print(\"Testing my best model\")\n",
        "print(\" \")\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "class_correct = list(0. for i in range(7))\n",
        "class_total = list(0. for i in range(7))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(test_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "        c = (predicted == target).squeeze()\n",
        "        for i in range(target.size(0)):\n",
        "            label = target[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "        if batch_idx % 5 == 0:\n",
        "            print(f'Processing batch {batch_idx + 1}/{len(test_loader)}... Current accuracy: {100 * correct / total:.1f}%')\n",
        "\n",
        "\n",
        "print(f'Final res:')\n",
        "print(\" \")\n",
        "print(f'Overall Test Accuracy: {100 * correct / total:.2f}%')\n",
        "print(f'Correct predictions: {correct}/{total}')\n",
        "\n",
        "print(f'Before Trans: ')\n",
        "print(\" \")\n",
        "for i in range(7):\n",
        "    if class_total[i] > 0:\n",
        "        accuracy = 100 * class_correct[i] / class_total[i]\n",
        "        print(f'{emotion_labels[i]:>8}: {accuracy:5.1f}% ({int(class_correct[i]):>3}/{int(class_total[i]):>3})')\n",
        "\n",
        "print(f'summary')\n",
        "print(\"\" )\n",
        "print(f'Training Accuracy:   98.3%')\n",
        "print(f'Validation Accuracy: 62.9%')\n",
        "print(f'Test Accuracy:       {100 * correct / total:.2f}%')\n",
        "\n",
        "test_acc = 100 * correct / total\n",
        "val_acc = 62.9\n",
        "if test_acc > val_acc + 2:\n",
        "    print(f'test > Val: Model generalizes well!')\n",
        "elif test_acc < val_acc - 5:\n",
        "    print(f'Test < Val: Possible overfitting detected')\n",
        "else:\n",
        "    print(f'Test ≈ Val: Good generalization')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zTySzbwtKQu",
        "outputId": "e587838f-4f44-47a4-8f76-87f822896512"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing my best model\n",
            " \n",
            "Processing batch 1/36... Current accuracy: 62.0%\n",
            "Processing batch 6/36... Current accuracy: 61.5%\n",
            "Processing batch 11/36... Current accuracy: 60.5%\n",
            "Processing batch 16/36... Current accuracy: 60.8%\n",
            "Processing batch 21/36... Current accuracy: 60.3%\n",
            "Processing batch 26/36... Current accuracy: 60.9%\n",
            "Processing batch 31/36... Current accuracy: 60.8%\n",
            "Processing batch 36/36... Current accuracy: 60.6%\n",
            "Final res:\n",
            " \n",
            "Overall Test Accuracy: 60.60%\n",
            "Correct predictions: 2175/3589\n",
            "Before Trans: \n",
            " \n",
            "   Angry:  45.0% (210/467)\n",
            " Disgust:  67.9% ( 38/ 56)\n",
            "    Fear:  39.5% (196/496)\n",
            "   Happy:  80.7% (722/895)\n",
            "     Sad:  50.8% (332/653)\n",
            "Surprise:  71.8% (298/415)\n",
            " Neutral:  62.4% (379/607)\n",
            "summary\n",
            "\n",
            "Training Accuracy:   98.3%\n",
            "Validation Accuracy: 62.9%\n",
            "Test Accuracy:       60.60%\n",
            "Test ≈ Val: Good generalization\n"
          ]
        }
      ]
    }
  ]
}