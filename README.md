# FER2013 Facial Expression Recognition Project

## პროექტის შესახებ

ამ კონტესტის ფარგლებში, გადმოგვეცემა Dataset(48x48 grayscale სურათები) და უნდა შევძლოთ სურათზე ასახული ადამიანის ემოციის ამოცნობა. დეთასეტი შეიცავს 35,887 სურათს 7 ემოციური კლასისგან: angry, disgust, fear, happy, sad, surprise და neutral. ამოცანა წარმოადგენს კლასიკურ კომპიუტერული ხედვის პრობლემას, სადაც საჭიროა CNN არქიტექტურების გამოყენება ოპტიმალური კლასიფიკაციის მიღწევისთვის.

მონაცემები განაწილებულია სამ ნაწილად: ტრენინგის სეტი 28,709 სურათით, საჯარო ტესტის სეტი 3,589 სურათით და პრივატული ტესტის სეტი 3,589 სურათით. ყველა სურათი წარმოდგენილია CSV ფორმატში, სადაც ყოველი პიქსელის მნიშვნელობა ჩაწერილია 0-255 დიაპაზონში.

პროექტის მიზანია სისტემატური მიდგომით შევისწავლოთ სხვადასხვა CNN არქიტექტურების ეფექტურობა ამ კონკრეტულ ამოცანაზე, დავიწყოთ მარტივი მოდელებიდან და თანდათანობით შევძინოთ სირთულე, რათა დავადგინოთ ოპტიმალური ბალანსი მოდელის complexity-სა და შესრულების ხარისხს შორის.

## ჩემი მიდგომის მოკლე მიმოხილვა

გადავწყვიტე ამოცანა რამდენიმე საფეხურად ჩამეშალა. შევქმენი 3 ექსპერიმენტი. პირველ ექსპერიმენტში გადავწყვიტე შემექმნა basic CNNs და დამენახა რა გავლენას ახდენს ლეიერების რაოდენობა მოდელზე. ამისათვის შევქმენი 1/3/5/7 ლეიერიანი CNNs და მათ შორის ავარჩიე საუკეთესო. რადგანაც უკვე ვიცით რა რაოდენობის ლეიერია საუკეთესო, ახლა ვიფიქროთ რა ნორმალიზაცია შეიძლება დაგვეხმაროს მის გაუმჯობესებაში. სწორედ ეს გავარკვიე მე-2 ექსპერიმენტში. დავტესტე Batchnorm, Dropout, Dropout+Batchnorm,Augmentation. კვლავ, მათ შორის ავარჩიე საუკეთესო და შემდეგ გადავედი მესამე ექსპერიმენტზე, რომელშიც ჩემს მოდელს დავუმატე ცოტა უფრო კომპლექსური არქიტექტურა. გამოვიყენე Attention, Skip Connections და ამ ორის კომბინაცია. შედეგად, მივიღე მოდელი, რომელიც ნელ-ნელა ავარჩიე.

## რეპოზიტორის სტრუქტურა

### data
init მაძლევს საშუალებას ფოტოების ვიზუალიზაციის, დეითას დისტრიბუციისა და სხვადასხვა მნიშვნელოვანი მაჩვენებლის დანახვაში და იმპლემენტირებაში.

### general_aid
**pytorch_importing** - იღებს pandas DataFrame-ს FER2013 data-ით, გარდაქმნის pixel string-ს → numpy array → PIL Image-ს, აბრუნებს (image, emotion) tuple-ს training-ისთვის. მაქვს data loading ფუნქციები. მოკლედ რომ ვთქვათ, FER2013 dataset-ის PyTorch-ში გამოსაყენებლად ამზადებს.

### my_models
იმპლემენტირებულია მოდელები, რომლებიც შემდეგ იწვრთნება შესაბამის ნოუთბუქებში, მაქვს 1/3/5/7 layer cnn, 5layer cnn + bathnorm/dropout/skipping/batchnorm + dropout/aug/batchnorm + attention/batchnorm + skipping/ batchnorm +skipping + combo.

ეს მოდელები იმპლემენტირებულია იმისათვის, რომ ჩამეტარებინა 3 ძირითადი ექსპერიმენტი, რომელიც მომცემდა საშუალებას დამედგინა რა იყო საუკეთესო მოდელი. პირველი ექსპერიმენტი ფოკუსირდებოდა ლეიერების გავლენაზე, მეორე - რეგულარიზაციასა და მესამე - ცოტა უფრო რთულ არქიტექტურაზე.

### Notebooks
აქ ვხვდებით Experiment Notebooks, data_testing, General_work_on_data, model_implementation_testing. ჩამოთვლილი ფაილებიდან ბოლო 3 იყო პირველი შეხება ამ დავაებასთან, 2 გვარად დავალოუდე დეითა და მოვახდინე უბრალოდ მათი ვიზუალიზაცია/ დისტრიბუციის ნახვა, მნიშვნელოვანი არაფერი ხდება ამ ნოუთბუქებში.ასევე მაქვს საბოლოო final_testing ნოუთბუქი,
სადაც უბრალოდ ტესტ სეტზე ვუშვებ ჩემს მოდელს.

Experiment Notebooks-ში ზემოთ აღწერილი მოდელების წვრთნას/wandb logging-ს, მრავალი საჭირო პარამეტრის დათვლასა და მოდელების შედარებას შეხვდებით. სწორედ მათი საშუალებით ვადგენ საუკეთესო მოდელს, ფაქტობრივად ესაა ყველაზე მნიშვნელოვანი ნაწილი.

### train_models_temp
აქ ხდება მოდელების წვრთვნისთვის საჭირო ფუნქციების იმპლემენტაცია, იმისთვის რომ ეს საქმე გამემარტივებინა ცოტათი, ჩავშალე 4 ნაწილად.

- **init.py** - საშუალებად მაძლევს გავამარტივო იმპორტები
- **helper.py** - set_seed(42) - ყველა random number generator-ს აყენებს იგივე seed-ს reproducible შედეგებისთვის, get_device() - ამოწმებს GPU ხელმისაწვდომია თუ არა, print_model_info(model, name) - აჩვენებს მოდელის პარამეტრების რაოდენობას, display_my_result(model_name, results) - ღრმა ანალიზით აჩვენებს ტრენინგის შედეგებს
- **my_trains.py** - ასევე ძალიან მნიშვნელოვანია, რადგან მოიცავს EmotionCNNTrainer კლასს, რომელიც ატრენინგებს მოდელებს, ამოწმებს ფიტს და ლოგავს wandb-ში ავტომატურად და ამასთან, ადარებს სხვადასხვა მოდელებს. მაქვს ფუნქცია, რომელიც თითოეულ მოდელს ატრეინებს, ხოლო my_trains ბოლოში კი შეხვდებით იმ ექსპერიმენტებს, რომლებიც რეალურად ჩავატარე და ექსპერიმენტების Notebook-ში ვიძახებ
- **plotting.py** - დამხმარე ფუნქციები, რომელიც მეხმარება მოდელების, მათი მახასიათებლებისა და ეფექტურობის ვიზუალიზაციაში და მანახებს ტრეინინგსაც

## ექსპერიმენტების დეტალური ანალიზი

### ექსპერიმენტი 1: არქიტექტურული სიღრმის ანალიზი

გამოვიყენე სისტემატური მიდგომა, დავიწყე ყველაზე მარტივი არქიტექტურიდან (1 ლეიერი) და თანდათანობით გავზარდე მათი რაოდენობა და შესაბამისად, სირთულე. რადგანაც მინდოდა ყველანაირი მოდელი გამეტესტა (თურმე მინიმალურ ცვლილებას ლეიერების რაოდენობაში ძალიან დიდი გავლენა აქვს მოდელზე)

#### შედეგების ანალიზი და ძირითადი გადაწყვეტილებები:

**1-ლეიერიანი CNN (51.6% ვალიდაციის სიზუსტე)**
დავადასტურე, რომ მოდელს არასაკმარისი capacity აქვს
- მტკიცებულება: ტრენინგის სიზუსტე მიაღწია 86.7%-ს, ხოლო ვალიდაცია 51.6%-ზე "გაიჭედა"
- ანალიზი: დიდი gap (35.1%) მიუთითებს რომ მოდელი ზედმეტად მარტივია რთული patterns-ის სასწავლელად
- გადაწყვეტილება: გავაგრძელე ლეიერების დამატება

**3-ლეიერიანი CNN (53.6% ვალიდაციის სიზუსტე)**
1 ლეიერიენთან შედარებით გაუმჯობესდა, მაგრამ ჯერ კიდევ არასაკმარისია
- მტკიცებულება: ვალიდაციაზე 2% გაუმჯობესება 1-ლეიერთან შედარებით
- ანალიზი: training accuracy 97.8% vs validation 53.6% - კვლავ ძლიერი overfitting
- გადაწყვეტილება: საჭიროა კიდევ უფრო ღრმა მოდელი უკეთესი feature learning-ისთვის

**5-ლეიერიანი CNN (55.6% ვალიდაციის სიზუსტე)**
ეს იქნება ყველაზე ნორმალური მოდელი.
- მტკიცებულება: საუკეთესო ვალიდაციის შედეგი (55.6%)
- ანალიზი: Train-val gap (36.9%) კვლავ მაღალია, მაგრამ ვალიდაციის accuracy ყველაზე კარგი აქვს
- აქვს ძალიან კარგი ბალანსი model capacity-სა და overfitting-ს შორის
- გადაწყვეტილება: ეს იქნება baseline არქიტექტურა შემდგომი ექსპერიმენტებისთვის

**7-ლეიერიანი CNN (24.5% ვალიდაციის სიზუსტე)**
ვიხილავთ, რომ ზედმეტი ლეიერები რეალურად აფუჭებს საქმეს
- მტკიცებულება: კატასტროფულად დაბალი accuracy (24.5% - random-ზე ცუდია)
- ანალიზი: მოდელი ვერ სწავლობს საერთოდ - vanishing gradient problem და აქვს ზედმეტად ბევრი ფიჩერი ამ dataset-ისთვის
- გადაწყვეტილება: 7+ ლეიერი ზედმეტია FER2013 dataset-ისთვის

**Performance Ranking:**
1. 5-ლეიერი (55.6%) - ყველაზე კარგი
2. 3-ლეიერი (53.6%) - საკმაოდ ნორმალური მოდელი
3. 1-ლეიერი (51.6%) - ზედმეტად მარტივი
4. 7-ლეიერი (24.5%) - სრულიად უვარგისი

**დასკვნა (მზადება ექსპერიმენტი 2-ისთვის):**
ამ დეითასეთისთვის მეტი სიღრმე ოპტიმიზაციის საშუალებას არ გვაძლევს, ნაკლები კი ძალიან მწირ capacity-ს გვაძლევს. მეორე ექსპერიმენტისთვის საბაზისოდ ავიღებ 5-ლეიერიან CNN-ს, რომლის მთავარი პრობლემაა: overfitting - train-val gap 35-45% და ახლა შევეცდები გამოვიყენო რეგულარიზაცია overfitting-ის შესამცირებლად

### ექსპერიმენტი 2: რეგულარიზაციის დამატება

რადგანაც წინა ექსპერიმენტიდან დავამტკიცეთ, რომ ყველაზე ოპტიმალურია 5 layer_cnn, ახლა შევეცადოთ მისი გაუმჯობესება რეგულარიზაციის საშუალებით. რეგულარიზაციის ტექნიკების შედარება

#### შედეგების ანალიზი და ძირითადი გადაწყვეტილებები:

**5-Layer Aug (32.4% ვალიდაციის სიზუსტე)**
Data Augmentation ზედმეტად აგრესიული აღმოჩნდა, თუმცა მოველოდი რომ ასე არ იქნებოდა (და საშინელი დასაწერია)
- მტკიცებულება: კატასტროფულად დაბალი accuracy (32.4%) - ყველაზე ცუდი შედეგი
- ანალიზი: Train accuracy მხოლოდ 51.5% - ეს მიუთითებს underfitting-ზე. Data augmentation-მა ზედმეტად გაართულა ლერნინგი
- გადაწყვეტილება: Data augmentation სრულიად უვარისი აღმოჩნდა ჩემს შემთხვევაში ამ დეითასეთისთვის

**5-Layer Dropout (59.3% ვალიდაციის სიზუსტე)**
Dropout გვაძლევს შედარებით კარგ შედეგს, მაგრამ არა იდეალურს
- მტკიცებულება: ვალიდაციის accuracy 59.3% - გაუმჯობესება basic 5-layer-თან შედარებით (55.6% → 59.3%)
- ანალიზი: Train-val gap 32.9% - კვლავ მაღალი, მაგრამ უკეთესი. Dropout ეხმარება overfitting-ის შემცირებაში
- გადაწყვეტილება: ამისდა მიუხედავად, მაინც ძალიან დიდი overfitting gap გვაქვს

**5-Layer Normalization (62.4% ვალიდაციის სიზუსტე)**
Batch Normalization ყველაზე ეფექტური მეთოდია
- მტკიცებულება: საუკეთესო ვალიდაციის შედეგი (62.4%)
- ანალიზი: Train accuracy 97.8% vs Validation 62.4% - overfitting კვლავ არსებობს, მაგრამ ვალიდაციის performance საუკეთესოა
- BatchNorm ასტაბილურებს თრეინინგს და გვაქვს სწრაფი convergence (20 epochs vs 26 dropout-ისთვის)
- გადაწყვეტილება: საკმაოდ კარგი მოდელია

**5-Layer Norm + Dropout (61.4% ვალიდაციის სიზუსტე)**
ეს კომბინაცია არ იძლევა იმ შედეგს, როგორსაც მოველოდი. მეგონა ბევრად უკეთესი იქნებოდა.
- მტკიცებულება: 61.4% accuracy - უკეთესია dropout-ზე, მაგრამ უარესია BatchNorm-ზე
- ანალიზი: Train-val gap 26.7% - ყველაზე პატარა gap, მაგრამ absolute performance დაბალი
- ორი რეგულარიზაციის მეთოდი ერთად შესაძლოა ზედმეტად ზღუდავს model capacity-ს
- გადაწყვეტილება: Over-regularization - მეტი კონტროლი ნაკლები performance-ით

**Performance Ranking:**
1. 5-Layer BatchNorm (62.4%) - ყველაზე კარგი
2. 5-Layer BatchNorm+Dropout (61.4%) - კარგი balance, მაგრამ უარესი performance
3. 5-Layer Dropout (59.3%) - საშუალო შედეგი
4. 5-Layer Augmentation (32.4%) - სრულიად უვარგისი

**დასკვნა (მზადება ექსპერიმენტი 3-ისთვის):**
- Batch Normalization: ყველაზე ეფექტური single technique
- Dropout: მუშაობს, მაგრამ BatchNorm-ზე ნაკლებად ეფექტურია
- Data Augmentation: ზედმეტად აგრესიული ამ შემთხვევაში და ყველაზე ცუდი შედეგი აქვს
- კომბინაციები: არ იძლევა მოსალოდნელ გაუმჯობესებას

შესაბამისად, batch normalization საუკეთესო გადაწყვეტილებაა ამ კონკრეტულ შემთხვევაში. ახლა კი შევეცდები ცოტა უფრო კომპლექსური არქიტექტურა ჩავამატო ჩემს მოდელში

### ექსპერიმენტი 3: უფრო კომპლექსური არქიტექტურის ჩამატება

მეორე ექსპერიმენტიდან დავადგინეთ, რომ ბეჩ ნორმალიზაცია იყო საუკეთესო მოდელი, შესაბამისად, ახლა მას გამოვიყენებ ბეისლაინად და მასზე დაყრდნობით ავაშენებ ახალ მოდელებს. ამჯერად ვიყენებ Attention, Skipping და ამათ კომბინაციას.

#### შედეგების ანალიზი და ძირითადი გადაწყვეტილებები:

**5-Layer BatchNorm + Attention (62.3% ვალიდაციის სიზუსტე):**
Channel Attention არ იძლევა მოსალოდნელ გაუმჯობესებას
- მტკიცებულება: 62.3% accuracy - ძალიან ახლოს baseline-თან (62.4%), მაგრამ ოდნავ უარესია
- ანალიზი: Train accuracy 97.0% vs Validation 62.3% - overfitting gap 34.7%
- Channel attention-მა დაამატა 45K პარამეტრი, მაგრამ არ გააუმჯობესა შედეგი, ამიტომ ვერ გაამართლა ჩემი მოლოდინები. FER2013-ის მცირე რეზოლუცია (48x48) შესაძლოა არასაკმარისია attention mechanisms-ის ეფექტური გამოყენებისთვის
- გადაწყვეტილება: Channel attention დიდად არ გამომადგა ამ დეითასეთისთვის

**5-Layer BatchNorm + Skip Connections (62.9% ვალიდაციის სიზუსტე):**
Skip Connections იძლევა საუკეთესო შედეგს სხვა არქიტექტურებთან შედარებით
- მტკიცებულება: 62.9% accuracy - საუკეთესო შედეგი, baseline-ის გადალახვა (62.4% → 62.9%)
- ანალიზი: Train accuracy 98.3% vs Validation 62.9% - კვლავ მაღალი overfitting (35.4%)
- შესაბამისად, skipping ეხმარება gradient flow-ს და ხდის training-ს უფრო სტაბილურს. ასევე, ყველაზე ხანგრძლივი training (29 epochs), რაც ნიშნავს უფრო სტაბილურ ლერნინგს
- გადაწყვეტილება: Skip connections ყველაზე ეფექტურია

**5-Layer BatchNorm + Combo (61.9% ვალიდაციის სიზუსტე):**
ზემოთ აღწერილი 2 ტექნიკის კომბინაცია უბრალოდ უფრო კომპლექსურს ხდის მოდელს და რეალურად არ აუმჯობესებს დიდად არაფერს
- მტკიცებულება: 61.9% accuracy - ყველაზე ცუდი შედეგი advanced models-იდან
- ანალიზი: Train accuracy 97.6% vs Validation 61.9% - overfitting gap 35.7%
- ყველაზე მეტი პარამეტრი (11.29M) აქვს ამას, მაგრამ ყველაზე ცუდი performance
- Attention + Skip Connections ერთად ქმნის ზედმეტ complexity-ს
- გადაწყვეტილება: "More techniques ≠ Better results" - over-engineering-ის კლასიკური მაგალითი

**Performance Ranking:**
1. 5-Layer BatchNorm + Skip (62.9%) - საუკეთესო advanced model
2. 5-Layer BatchNorm + Attention (62.3%) - ახლოს baseline-თან
3. 5-Layer BatchNorm + Combo (61.9%) - over-engineering-ის მსხვერპლი

**დასკვნა:**
- Skip Connections: ერთადერთი ტექნიკა, რომელიც რეალურად აუმჯობესებს baseline-ს
- Channel Attention: არ არის ეფექტური მცირე რეზოლუციის სურათებისთვის
- კომბინირებული მიდგომა: complexity-ის მატება performance-ის გაუარესებას იწვევს
- Overfitting პრობლემა: ყველა advanced model აჩვენებს მნიშვნელოვან overfitting-ს

ამ კონკრეტული ექსპერიმენტიდან ვისწავლე, რომ გარულება არ ნიშნავს გაუმჯობესებას...

## საბოლოო შედეგები

**საუკეთესო მოდელი ტესტირებულებიდან:** 5-Layer BatchNorm + Skip Connections (62.9%)

**პროექტის მთლიანი მიღწევა:**
წავიდა 55.6% (basic 5-layer) → 62.4% (+ BatchNorm) → 62.9% (+ Skip Connections) systematic approach-ით და შევისწავლე თითოეული architectural decision-ის ეფექტი.


* data folder და რანდენიმე ნოუთბუქი წავშალე, რადგან ძალიან
* დიდი ზომის იყო და დიდი დრო მიჰქონდა ატვირთვას


# ლინკები ჩემი რეპორტებისათვის
- **Advanced Architrecture Report**: [ Report](https://wandb.ai/kechik21-free-university-of-tbilisi-/advanced_architecture_experiment/reports/FER2013-Facial-Expression-Recognition-Complex-Model-Analysis--VmlldzoxMzEwOTM2MA?accessToken=gcta5q44nec07rwml5tmxale22d2zxu4tmfu7gi7u7lzf64v1nvyevbdpz8ko359)


- **Regularization Report**: [ Report](https://wandb.ai/kechik21-free-university-of-tbilisi-/regularization_exp/reports/FER2013-Facial-Expression-Recognition-Regularization-Model-Analysis--VmlldzoxMzEwOTI3Ng?accessToken=cvzrynkepzwmippufwzd21808d16bpra5odzcvs8uvj7i8y14ypyklb3uyvj1qsl)


- **Model Depth Report**: [ Report](https://wandb.ai/kechik21-free-university-of-tbilisi-/depth_experiment/reports/FER2013-Facial-Expression-Recognition-Depth-Model-Analysis--VmlldzoxMzEwODkwNA?accessToken=68evwzjbbuwvht3ywjtqw7h7hqtban7xakg1cllohygdw6xk5p3im5ds0mvyo459)


რადგან თიმსით მქონდა შექმნილი პროექტები, მოგიწვიეთ თიმსში...
[Profile Link](https://wandb.ai/kechik21-free-university-of-tbilisi-?shareProfileType=copy)
პროფილზე არსებული advanced_architecure_experiment, regularization_experiiment & depth_experiment are for this homewok.


